{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üöÄ Fraud Detection Model Training with MLflow\n",
        "\n",
        "This notebook demonstrates the **complete ML workflow**:\n",
        "1. **Data Loading** from PostgreSQL/MySQL\n",
        "2. **Feature Engineering** \n",
        "3. **Model Training** with experiment tracking\n",
        "4. **Model Evaluation** and comparison\n",
        "5. **Model Registration** in MLflow\n",
        "6. **Model Deployment** to production API\n",
        "\n",
        "## üéØ Best Practices Implemented:\n",
        "- ‚úÖ **Experiment tracking** with MLflow\n",
        "- ‚úÖ **Model versioning** and comparison\n",
        "- ‚úÖ **Automated feature engineering**\n",
        "- ‚úÖ **Cross-validation** and metrics logging\n",
        "- ‚úÖ **Model artifacts** preservation\n",
        "- ‚úÖ **Production deployment** integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import psycopg2\n",
        "import mysql.connector\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# üîß MLflow Configuration\n",
        "mlflow.set_tracking_uri(\"http://localhost:5002\")\n",
        "mlflow.set_experiment(\"fraud-detection-training\")\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üéØ MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"üìä Current experiment: {mlflow.get_experiment_by_name('fraud-detection-training')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üíæ Data Loading Functions\n",
        "def load_data_from_postgres():\n",
        "    \"\"\"Load transaction data from PostgreSQL\"\"\"\n",
        "    try:\n",
        "        conn = psycopg2.connect(\n",
        "            host=\"localhost\",\n",
        "            port=5432,\n",
        "            database=\"bigdata\",\n",
        "            user=\"bigdata_user\",\n",
        "            password=\"bigdata_pass\"\n",
        "        )\n",
        "        \n",
        "        # Load sample transaction data (you can modify this query)\n",
        "        query = \"\"\"\n",
        "        SELECT \n",
        "            transaction_id,\n",
        "            customer_id,\n",
        "            merchant_id,\n",
        "            amount,\n",
        "            merchant_category,\n",
        "            timestamp,\n",
        "            CASE \n",
        "                WHEN amount > 1000 AND merchant_category = 'online' THEN 1 \n",
        "                WHEN amount > 5000 THEN 1\n",
        "                ELSE 0 \n",
        "            END as is_fraud\n",
        "        FROM (\n",
        "            SELECT \n",
        "                'txn_' || generate_series(1, 10000) as transaction_id,\n",
        "                'cust_' || (random() * 1000)::int as customer_id,\n",
        "                'merch_' || (random() * 500)::int as merchant_id,\n",
        "                (random() * 10000)::numeric(10,2) as amount,\n",
        "                (ARRAY['retail', 'online', 'grocery', 'gas', 'restaurant'])[floor(random() * 5 + 1)] as merchant_category,\n",
        "                NOW() - (random() * interval '30 days') as timestamp\n",
        "        ) t\n",
        "        \"\"\"\n",
        "        \n",
        "        df = pd.read_sql(query, conn)\n",
        "        conn.close()\n",
        "        print(f\"‚úÖ Loaded {len(df)} transactions from PostgreSQL\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading from PostgreSQL: {e}\")\n",
        "        return generate_synthetic_data()\n",
        "\n",
        "def generate_synthetic_data():\n",
        "    \"\"\"Generate synthetic fraud detection data for training\"\"\"\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "    \n",
        "    data = {\n",
        "        'transaction_id': [f'txn_{i}' for i in range(n_samples)],\n",
        "        'customer_id': [f'cust_{np.random.randint(1, 1000)}' for _ in range(n_samples)],\n",
        "        'merchant_id': [f'merch_{np.random.randint(1, 500)}' for _ in range(n_samples)],\n",
        "        'amount': np.random.exponential(100, n_samples),\n",
        "        'merchant_category': np.random.choice(['retail', 'online', 'grocery', 'gas', 'restaurant'], n_samples),\n",
        "        'hour': np.random.randint(0, 24, n_samples),\n",
        "        'day_of_week': np.random.randint(0, 7, n_samples),\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Create fraud labels based on business rules\n",
        "    df['is_fraud'] = (\n",
        "        ((df['amount'] > 1000) & (df['merchant_category'] == 'online')) |\n",
        "        (df['amount'] > 5000) |\n",
        "        ((df['hour'] < 6) & (df['amount'] > 500))\n",
        "    ).astype(int)\n",
        "    \n",
        "    print(f\"‚úÖ Generated {len(df)} synthetic transactions\")\n",
        "    print(f\"üìä Fraud rate: {df['is_fraud'].mean():.2%}\")\n",
        "    return df\n",
        "\n",
        "# Load the data\n",
        "print(\"üîÑ Loading transaction data...\")\n",
        "df = load_data_from_postgres()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß Feature Engineering Pipeline\n",
        "def create_features(df):\n",
        "    \"\"\"Create features for fraud detection\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Amount-based features\n",
        "    df['amount_log'] = np.log1p(df['amount'])\n",
        "    df['amount_zscore'] = (df['amount'] - df['amount'].mean()) / df['amount'].std()\n",
        "    df['is_high_amount'] = (df['amount'] > df['amount'].quantile(0.95)).astype(int)\n",
        "    \n",
        "    # Time-based features (if timestamp exists)\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "        df['hour'] = df['timestamp'].dt.hour\n",
        "        df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "        df['is_night'] = ((df['hour'] < 6) | (df['hour'] > 22)).astype(int)\n",
        "    \n",
        "    # Merchant category encoding\n",
        "    le_merchant = LabelEncoder()\n",
        "    df['merchant_category_encoded'] = le_merchant.fit_transform(df['merchant_category'])\n",
        "    \n",
        "    # Customer frequency features (simplified)\n",
        "    customer_counts = df['customer_id'].value_counts()\n",
        "    df['customer_frequency'] = df['customer_id'].map(customer_counts)\n",
        "    df['is_new_customer'] = (df['customer_frequency'] == 1).astype(int)\n",
        "    \n",
        "    # Merchant frequency features\n",
        "    merchant_counts = df['merchant_id'].value_counts()\n",
        "    df['merchant_frequency'] = df['merchant_id'].map(merchant_counts)\n",
        "    df['is_new_merchant'] = (df['merchant_frequency'] == 1).astype(int)\n",
        "    \n",
        "    print(\"‚úÖ Feature engineering completed\")\n",
        "    print(f\"üìä Total features created: {len([col for col in df.columns if col not in ['transaction_id', 'customer_id', 'merchant_id', 'timestamp', 'is_fraud']])}\")\n",
        "    \n",
        "    return df, le_merchant\n",
        "\n",
        "# Apply feature engineering\n",
        "print(\"üîÑ Creating features...\")\n",
        "df_features, merchant_encoder = create_features(df)\n",
        "\n",
        "# Select features for modeling\n",
        "feature_columns = [\n",
        "    'amount', 'amount_log', 'amount_zscore', 'is_high_amount',\n",
        "    'hour', 'day_of_week', 'is_weekend', 'is_night',\n",
        "    'merchant_category_encoded', 'customer_frequency', 'is_new_customer',\n",
        "    'merchant_frequency', 'is_new_merchant'\n",
        "]\n",
        "\n",
        "X = df_features[feature_columns]\n",
        "y = df_features['is_fraud']\n",
        "\n",
        "print(f\"üìä Feature matrix shape: {X.shape}\")\n",
        "print(f\"üìä Target distribution: {y.value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Model Training with MLflow Experiments\n",
        "def train_and_log_model(model, model_name, X_train, X_test, y_train, y_test, scaler=None):\n",
        "    \"\"\"Train model and log everything to MLflow\"\"\"\n",
        "    \n",
        "    with mlflow.start_run(run_name=f\"{model_name}_experiment\"):\n",
        "        # Log parameters\n",
        "        if hasattr(model, 'get_params'):\n",
        "            mlflow.log_params(model.get_params())\n",
        "        \n",
        "        # Scale features if needed\n",
        "        if scaler:\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            mlflow.log_param(\"feature_scaling\", \"StandardScaler\")\n",
        "        else:\n",
        "            X_train_scaled = X_train\n",
        "            X_test_scaled = X_test\n",
        "            mlflow.log_param(\"feature_scaling\", \"None\")\n",
        "        \n",
        "        # Train model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        \n",
        "        if y_pred_proba is not None:\n",
        "            auc = roc_auc_score(y_test, y_pred_proba)\n",
        "            mlflow.log_metric(\"auc\", auc)\n",
        "        \n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "        mlflow.log_metric(\"precision\", precision)\n",
        "        mlflow.log_metric(\"recall\", recall)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n",
        "        \n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='f1_weighted')\n",
        "        mlflow.log_metric(\"cv_f1_mean\", cv_scores.mean())\n",
        "        mlflow.log_metric(\"cv_f1_std\", cv_scores.std())\n",
        "        \n",
        "        # Log model\n",
        "        if scaler:\n",
        "            # Create a pipeline for models that need scaling\n",
        "            from sklearn.pipeline import Pipeline\n",
        "            pipeline = Pipeline([\n",
        "                ('scaler', scaler),\n",
        "                ('model', model)\n",
        "            ])\n",
        "            mlflow.sklearn.log_model(pipeline, \"model\")\n",
        "        else:\n",
        "            mlflow.sklearn.log_model(model, \"model\")\n",
        "        \n",
        "        # Log feature importance if available\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': feature_columns,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            \n",
        "            # Save feature importance as artifact\n",
        "            feature_importance.to_csv(\"feature_importance.csv\", index=False)\n",
        "            mlflow.log_artifact(\"feature_importance.csv\")\n",
        "        \n",
        "        print(f\"‚úÖ {model_name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc if y_pred_proba is not None else 'N/A'}\")\n",
        "        \n",
        "        return model, {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'auc': auc if y_pred_proba is not None else None\n",
        "        }\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"üìä Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
        "\n",
        "# Initialize models to compare\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Train all models\n",
        "results = {}\n",
        "print(\"\\nüöÄ Training models with MLflow tracking...\")\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nüîÑ Training {model_name}...\")\n",
        "    \n",
        "    # Use scaler for LogisticRegression\n",
        "    scaler = StandardScaler() if model_name == 'LogisticRegression' else None\n",
        "    \n",
        "    trained_model, metrics = train_and_log_model(\n",
        "        model, model_name, X_train, X_test, y_train, y_test, scaler\n",
        "    )\n",
        "    results[model_name] = metrics\n",
        "\n",
        "print(\"\\n‚úÖ All models trained and logged to MLflow!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Model Comparison and Selection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compare results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"üèÜ Model Performance Comparison:\")\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Find best model\n",
        "best_model_name = results_df['f1_score'].idxmax()\n",
        "print(f\"\\nü•á Best model: {best_model_name} (F1: {results_df.loc[best_model_name, 'f1_score']:.4f})\")\n",
        "\n",
        "# Plot comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Metrics comparison\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\n",
        "results_df[metrics_to_plot].plot(kind='bar', ax=axes[0])\n",
        "axes[0].set_title('Model Performance Metrics')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# AUC comparison\n",
        "auc_data = results_df['auc'].dropna()\n",
        "auc_data.plot(kind='bar', ax=axes[1], color='orange')\n",
        "axes[1].set_title('AUC Scores')\n",
        "axes[1].set_ylabel('AUC')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Log the comparison chart to MLflow\n",
        "with mlflow.start_run(run_name=\"model_comparison\"):\n",
        "    mlflow.log_artifact('model_comparison.png')\n",
        "    \n",
        "    # Log the best model metrics\n",
        "    for metric, value in results_df.loc[best_model_name].items():\n",
        "        if value is not None:\n",
        "            mlflow.log_metric(f\"best_{metric}\", value)\n",
        "    \n",
        "    mlflow.log_param(\"best_model\", best_model_name)\n",
        "\n",
        "print(\"‚úÖ Model comparison logged to MLflow\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Model Registration and Deployment\n",
        "# Register the best model in MLflow Model Registry\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "\n",
        "# Get the run with the best model\n",
        "experiment = mlflow.get_experiment_by_name(\"fraud-detection-training\")\n",
        "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
        "\n",
        "# Find the run with the best F1 score\n",
        "best_run = runs.loc[runs['metrics.f1_score'].idxmax()]\n",
        "best_run_id = best_run['run_id']\n",
        "\n",
        "print(f\"üéØ Best run ID: {best_run_id}\")\n",
        "print(f\"üèÜ Best F1 score: {best_run['metrics.f1_score']:.4f}\")\n",
        "\n",
        "# Register the model\n",
        "model_name = \"fraud_detection_model\"\n",
        "model_version = mlflow.register_model(\n",
        "    model_uri=f\"runs:/{best_run_id}/model\",\n",
        "    name=model_name\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model registered as '{model_name}' version {model_version.version}\")\n",
        "\n",
        "# Transition to Production stage\n",
        "client.transition_model_version_stage(\n",
        "    name=model_name,\n",
        "    version=model_version.version,\n",
        "    stage=\"Production\"\n",
        ")\n",
        "\n",
        "print(f\"üöÄ Model version {model_version.version} moved to Production stage\")\n",
        "\n",
        "# Add model description and tags\n",
        "client.update_model_version(\n",
        "    name=model_name,\n",
        "    version=model_version.version,\n",
        "    description=f\"Fraud detection model using {best_model_name} algorithm. \"\n",
        "               f\"Trained on {len(df)} transactions with F1 score: {best_run['metrics.f1_score']:.4f}\"\n",
        ")\n",
        "\n",
        "client.set_model_version_tag(\n",
        "    name=model_name,\n",
        "    version=model_version.version,\n",
        "    key=\"algorithm\",\n",
        "    value=best_model_name\n",
        ")\n",
        "\n",
        "client.set_model_version_tag(\n",
        "    name=model_name,\n",
        "    version=model_version.version,\n",
        "    key=\"data_version\",\n",
        "    value=\"v1.0\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model metadata updated\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç Test Production Model Loading\n",
        "# Test loading the registered model\n",
        "loaded_model = mlflow.sklearn.load_model(f\"models:/{model_name}/Production\")\n",
        "\n",
        "# Test prediction on a sample\n",
        "sample_transaction = X_test.iloc[0:1]\n",
        "prediction = loaded_model.predict(sample_transaction)\n",
        "prediction_proba = loaded_model.predict_proba(sample_transaction)\n",
        "\n",
        "print(\"üß™ Testing Production Model:\")\n",
        "print(f\"üìä Sample features: {sample_transaction.iloc[0].to_dict()}\")\n",
        "print(f\"üéØ Prediction: {'FRAUD' if prediction[0] == 1 else 'LEGITIMATE'}\")\n",
        "print(f\"üìà Fraud probability: {prediction_proba[0][1]:.4f}\")\n",
        "\n",
        "# Test the API endpoint (if running)\n",
        "import requests\n",
        "import json\n",
        "\n",
        "try:\n",
        "    # Test API endpoint\n",
        "    api_url = \"http://localhost:5001/api/v1/predict\"\n",
        "    \n",
        "    # Create a test transaction with required fields\n",
        "    test_transaction = {\n",
        "        \"transaction_id\": \"test_001\",\n",
        "        \"customer_id\": \"cust_123\",\n",
        "        \"merchant_id\": \"merch_456\", \n",
        "        \"amount\": 1500.00,\n",
        "        \"merchant_category\": \"online\",\n",
        "        \"timestamp\": \"2025-01-04T15:30:00Z\"\n",
        "    }\n",
        "    \n",
        "    response = requests.post(api_url, json=test_transaction)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        api_result = response.json()\n",
        "        print(f\"\\nüåê API Test Result:\")\n",
        "        print(f\"üéØ Fraud Probability: {api_result['fraud_probability']}\")\n",
        "        print(f\"üìä Risk Level: {api_result['risk_level']}\")\n",
        "        print(f\"‚ö° Model Version: {api_result['model_version']}\")\n",
        "    else:\n",
        "        print(f\"‚ùå API Error: {response.status_code} - {response.text}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not test API: {e}\")\n",
        "    print(\"üí° Make sure the fraud detection API is running on localhost:5001\")\n",
        "\n",
        "print(\"\\nüéâ Training pipeline completed successfully!\")\n",
        "print(\"üîó Next steps:\")\n",
        "print(\"1. üìä Visit MLflow UI: http://localhost:5002\")\n",
        "print(\"2. üîç Check experiment runs and model registry\")\n",
        "print(\"3. üìà Compare model performance metrics\")\n",
        "print(\"4. üöÄ Deploy the best model to production\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
